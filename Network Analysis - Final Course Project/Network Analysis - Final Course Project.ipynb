{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting\n",
    "\n",
    "Beeradvocate is many things:\n",
    "\n",
    "a website built by beer enthusiasts for beer enthusiasts;\n",
    "a forum;\n",
    "a network;\n",
    "a marketplace;\n",
    "a cognitive device that assists users in navigating the beer market;\n",
    "a social valuation device;\n",
    "a unique source of data to conduct market research\n",
    "\n",
    "\n",
    "Problem\n",
    "\n",
    "Beeradvocate people want to put the platform into a better economic/financial position\n",
    "\n",
    "in order to do that, it is key to increase the traffic (advertisers will pay more!!)\n",
    "the company is evaluating two, non-mutually exclusive, alternatives: a) pushing occasional users to engage with the platform on a more regular basis; b) pushing heavy users to explore portions of the platforms they are less familiar with\n",
    "\n",
    "Instructions\n",
    "\n",
    "help the Beeradvocate people to reach their goal by building a recommender that provides users with consumption/review suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:39:35.508197Z",
     "start_time": "2018-12-13T02:39:35.500977Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import csv\n",
    "import datetime as dt\n",
    "from igraph import Graph as IGraph\n",
    "from igraph import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:39:56.955953Z",
     "start_time": "2018-12-13T02:39:52.434787Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usr_usr = pd.read_csv(\"Data/user_user_graph.csv\", header = None)\n",
    "pop = pd.read_csv(\"Data/popular_beer.csv\")\n",
    "usr_int = pd.read_csv(\"Data/all_user_interactions.csv\")\n",
    "beer_att = pd.read_csv(\"Data/gb_beer_attributes.csv\")\n",
    "beers = pd.read_csv(\"Data/gb_beers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:40:13.801438Z",
     "start_time": "2018-12-13T02:40:13.795165Z"
    }
   },
   "outputs": [],
   "source": [
    "# store beerID to beerName mapping\n",
    "beer_list = beers[['beer','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:40:31.009348Z",
     "start_time": "2018-12-13T02:40:30.999974Z"
    }
   },
   "outputs": [],
   "source": [
    "beer_list = beer_list.drop_duplicates(subset='beer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:40:55.201306Z",
     "start_time": "2018-12-13T02:40:48.320880Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% community detection as per the Community detection algorithm of Latapy & Pons\n",
    "# make edgelist\n",
    "edges = []\n",
    "\n",
    "with open('Data/user_user_weighted_graph.csv', 'r') as ifile:\n",
    "    for row in csv.reader(ifile.read().splitlines()):\n",
    "        element = str(row[0]).split()\n",
    "        u, v, weight = [i for i in element]\n",
    "        edges.append((u, v, float(weight)))\n",
    "        \n",
    "g = IGraph.TupleList(edges, directed=False, vertex_name_attr='name', edge_attrs=None, weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:41:12.422639Z",
     "start_time": "2018-12-13T02:41:12.353079Z"
    }
   },
   "outputs": [],
   "source": [
    "# funtion that shortlist beers by user's community\n",
    "def beer_by_com (g, usr_id, edges, beer_rev):\n",
    "    def detect_community (edge_list):\n",
    "        # use IGraph to covert edgelist into a network graph  \n",
    "        names = g.vs[\"name\"]\n",
    "        weights = g.es[\"weight\"]\n",
    "\n",
    "        # find clusters with \"walkstrap\" method\n",
    "        clusters = IGraph.community_walktrap(g, weights=weights).as_clustering()\n",
    "        nodes = [{\"name\": node[\"name\"]} for node in g.vs]\n",
    "\n",
    "        # store communities to user_id mapping\n",
    "        community = {}\n",
    "        for node in nodes:\n",
    "            idx = g.vs.find(name=node[\"name\"]).index\n",
    "            node[\"community\"] = clusters.membership[idx]\n",
    "            if node[\"community\"] not in community:\n",
    "                community[node[\"community\"]] = [node[\"name\"]]\n",
    "            else:\n",
    "                community[node[\"community\"]].append(node[\"name\"])\n",
    "\n",
    "        return community\n",
    "    \n",
    "    # funtion to return key in a dictionary if a value is detected in the key-value pair\n",
    "    def find_key(input_dict, value):\n",
    "        return next((k for k, v in input_dict.items() if value in v), None)\n",
    "    \n",
    "    community = detect_community(edges)\n",
    "    \n",
    "    #%% find top beers in each community\n",
    "\n",
    "    # extract username to userid mapping\n",
    "    beer_rev.loc[:, 'usr_name'] = beer_rev['usr'].str.split(\n",
    "            '.').str.get(0)\n",
    "    beer_rev.loc[:, 'usr_id'] = beer_rev['usr'].str.split(\n",
    "            '.').str.get(1).str.strip('.')\n",
    "    \n",
    "    # find user's community membership \n",
    "    com_list = []\n",
    "    for index, row in beer_rev.iterrows():\n",
    "        com_list.append(find_key(community, row['usr_id']))\n",
    "    beer_rev.loc[:, 'com'] = com_list\n",
    "\n",
    "    # keep reviews from users that exist in the usr-interaction network\n",
    "    beer_rev.dropna(subset=['com'], inplace=True)\n",
    "\n",
    "    # find average score for each beer by community\n",
    "    beer_rev.loc[:, 'rev_ave'] = 0\n",
    "    gr2 = beer_rev.groupby(['beer','com'], as_index=False)\n",
    "    beer_com = pd.DataFrame(gr2['bascore_norm'].aggregate(np.mean))\n",
    "\n",
    "    # extract top beers from each community\n",
    "    community_top = {}\n",
    "    for k in community.items():\n",
    "        subset = beer_com.loc[beer_com['com'] == k[0]]\n",
    "        list = []\n",
    "        for index, row in subset.iterrows():\n",
    "            # select beers in the first quantile of score distribution in a community\n",
    "            if row['bascore_norm']>= max(subset['bascore_norm']*0.75):\n",
    "                list.append(row['beer'])\n",
    "        community_top.update({k[0]:list})\n",
    "        \n",
    "    # find the community user belongs to\n",
    "    membership = find_key(community,usr_id)\n",
    "    return community_top.get(membership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Process for User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:41:37.904206Z",
     "start_time": "2018-12-13T02:41:29.492724Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2878: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/anaconda3/lib/python2.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/anaconda3/lib/python2.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/anaconda3/lib/python2.7/site-packages/pandas/core/indexing.py:630: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "# import and reshape dataset to extract user id\n",
    "df = usr_int\n",
    "df.loc[:, 'usr'] = df['usr'].str.split('.').str.get(1).str.strip('/')\n",
    "\n",
    "# drop housekeeping column\n",
    "df.drop('call', axis=1, inplace=True) \n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# calculate the total activity of each user\n",
    "# total activity proxied by number of posts/threads\n",
    "df.loc[:,'count']=1\n",
    "activity = df.groupby(['usr'])['count'].aggregate(np.sum)\n",
    "\n",
    "# construct a new dataframe containing unique user and corresponding activity \n",
    "usr = df['usr'].drop_duplicates()\n",
    "usr_activity = pd.DataFrame(columns = ['usr','activity'])\n",
    "usr_activity.loc[:,'usr'] = list(usr)\n",
    "usr_activity.loc[:,'activity'] = list(activity)\n",
    "\n",
    "# import another dataset and extract user id\n",
    "df2 = pd.read_csv('Data/gb_beer_reviewers_attributes.csv')\n",
    "df2.loc[:, 'usr'] = df2['usr'].str.split('.').str.get(1)\n",
    "\n",
    "# extract unique users and him/her join time\n",
    "usr2 = df2['usr'].drop_duplicates()\n",
    "jointime = df2.query(\"var == 'joined'\")\n",
    "\n",
    "# clean the jointime into universal string format\n",
    "jointime = jointime.reset_index(drop = True)\n",
    "time = jointime.loc[jointime['value'].isin(['Yesterday','Wednesday','Saturday','Monday','Tuesday','Friday','Thursday']) == False]\n",
    "time['value'][71]='Sep 2, 2005'\n",
    "\n",
    "# transform the string format into timestamp \n",
    "time.loc[:, 'date_time'] = ''\n",
    "time.loc[:,'date_time'] = pd.to_datetime(time['value'], format='%b %d, %Y')\n",
    "\n",
    "# calculating the tenure based on jointime\n",
    "time.loc[:,'present'] = pd.Timestamp('2018-12-10')\n",
    "time.loc[:,'tenure'] = (time.present-time.date_time).astype('timedelta64[h]')\n",
    "time = time.drop_duplicates()\n",
    "\n",
    "# merge the tenure and activity of users\n",
    "usr_level = pd.merge(time,usr_activity,on='usr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:41:54.569512Z",
     "start_time": "2018-12-13T02:41:54.557486Z"
    }
   },
   "outputs": [],
   "source": [
    "def profile(usr_id,usr_level):\n",
    "    # set the formula of activity level which is total activity divided by tenure\n",
    "    usr_level.loc[:,'level'] = usr_level.activity/usr_level.tenure\n",
    "    # define users whose activity level is within the top 1/3 as 'heavy users', otherwise 'occational users'\n",
    "    usr_level.loc[:,'category'] = ''\n",
    "    threshold  = np.percentile(usr_level['level'], 66.67)\n",
    "    a = usr_level['level']\n",
    "\n",
    "    l = []\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        if a[i] >= threshold: \n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "            \n",
    "    usr_level['category'] = l\n",
    "    category = usr_level[usr_level.usr == usr_id].category.item()\n",
    "    \n",
    "    return category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbour's Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:42:11.350525Z",
     "start_time": "2018-12-13T02:42:11.314888Z"
    }
   },
   "outputs": [],
   "source": [
    "def NN(tar_usr,user_user_graph,popular,gb_beer_reviews):\n",
    "\n",
    "    #Import data\n",
    "    df = user_user_graph\n",
    "    popular = popular\n",
    "    beer_usr_rtdate = gb_beer_reviews\n",
    "    \n",
    "    #Data cleaning extract 'src' and 'tgt'\n",
    "    df.loc[:, 'src'] = df[0].str.split(' ').str.get(0)\n",
    "    df.loc[:, 'tgt'] = df[0].str.split(' ').str.get(1)\n",
    "    df.drop(0, axis=1, inplace=True)\n",
    "\n",
    "    #Creat a network \n",
    "    G = nx.from_pandas_edgelist(df, source='src', target='tgt')\n",
    "\n",
    "    #Find the neighbors of the input user\n",
    "    usr_N = G.neighbors(tar_usr)\n",
    "\n",
    "    #Find the neighbor's neighbor using loops\n",
    "    for i in usr_N:\n",
    "        usr_NN = list(G.neighbors(i))\n",
    "\n",
    "    #Put neighbor's neighbor into a dataframe\n",
    "    usr_NsN = pd.DataFrame(usr_NN, columns=['usr'])\n",
    "\n",
    "    #Extract the user ID\n",
    "    beer_usr_rtdate.loc[:, 'usr'] = beer_usr_rtdate['usr'].str.split('.').str.get(1)\n",
    "\n",
    "    #merge user and popular on beer ID\n",
    "    usr_NN_beer = usr_NsN.merge(beer_usr_rtdate,on='usr')\n",
    "\n",
    "    usr_NN_beer = usr_NN_beer.merge(popular,on='beer')\n",
    "\n",
    "    usr_NN_beer = usr_NN_beer.drop_duplicates('beer')\n",
    "\n",
    "    #Find top_3 beer according popularity\n",
    "    usr_NN_beer = usr_NN_beer.sort_values(by=['popular'], ascending= False)\n",
    "\n",
    "    #select the top 3 beers for neighbor's neighbor\n",
    "    top3 = usr_NN_beer.iloc[0:3, :] \n",
    "\n",
    "    #crop the data without the top 3 beers to avoid duplication\n",
    "    df_no_top3 = usr_NN_beer.iloc[3:,:]\n",
    "\n",
    "    #select 3 beers at random\n",
    "    df_no_top3 = df_no_top3.sample(n = 3)\n",
    "\n",
    "    #the top 6 beers with 3 top popular beers and 3 randomly selected beers\n",
    "    top6 = list(top3['beer'])+ list(df_no_top3['beer'])\n",
    "\n",
    "    return top6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:42:28.323110Z",
     "start_time": "2018-12-13T02:42:28.289577Z"
    }
   },
   "outputs": [],
   "source": [
    "def hub(beer_usr_rtdate, g):\n",
    "    \n",
    "    # Prepare the gb_beer_reviews data\n",
    "    beer_usr_rtdate.loc[:, 'usr'] = beer_usr_rtdate['usr'].str.split('.').str.get(1)\n",
    "    \n",
    "    #%% Find hubs\n",
    "    \n",
    "    # Calculate top 100 betweenness centrality of user network\n",
    "    btvs = []\n",
    "    for p in zip(g.vs, g.betweenness()):\n",
    "        btvs.append({\"name\": p[0][\"name\"], \"bt\": p[1]})\n",
    "    user_user_weighted_bc = sorted(btvs, key=lambda k: k['bt'], reverse=True)[:100]\n",
    "    \n",
    "    # Get the hub list\n",
    "    hub_nodes_list = []\n",
    "    for i in range(len(user_user_weighted_bc)):\n",
    "        hub_nodes_list.append(user_user_weighted_bc[i].get('name'))\n",
    "    \n",
    "    #%% The beers reviewed and scored by the hubs\n",
    "    \n",
    "    beer_rtdate = beer_usr_rtdate\n",
    "    \n",
    "    # slice beers reviewed in last 3 months\n",
    "    beer_rtdate['date'] = pd.to_datetime(beer_rtdate['date'], errors='coerce')\n",
    "    beer_rtdate['year'] = beer_rtdate['date'].dt.year\n",
    "    beer_rtdate['month'] = beer_rtdate['date'].dt.month\n",
    "    beer_rtdate = beer_rtdate[beer_rtdate.year == 2018]\n",
    "    beer_rtdate = beer_rtdate[beer_rtdate.month >= 9]\n",
    "    \n",
    "    # slice beers scored >= 4\n",
    "    beer_rtdate = beer_rtdate[beer_rtdate.bascore_norm >= 4]\n",
    "    \n",
    "    # Prepare beer data for hubs\n",
    "    hub_nodes_df = pd.DataFrame(hub_nodes_list, columns=['hub'])\n",
    "    hub_nodes_df.rename(columns={\"hub\": \"usr\"}, inplace=True)\n",
    "    \n",
    "    hub_beers_df = hub_nodes_df.merge(beer_rtdate,on='usr')\n",
    "    hub_beers_df = hub_beers_df.drop_duplicates('beer')\n",
    "    \n",
    "    # Randomly selected from hub beers\n",
    "    hub_beers_sample = hub_beers_df.sample(n = 20)\n",
    "    \n",
    "    # Generate the hub beers list\n",
    "    hub_beers_list = hub_beers_sample['beer'].tolist()\n",
    "    \n",
    "    return hub_beers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:42:45.135525Z",
     "start_time": "2018-12-13T02:42:45.119369Z"
    }
   },
   "outputs": [],
   "source": [
    "def recommend (usr_id, usr_level, g, edges, usr_usr, pop, beer_list):\n",
    "    \n",
    "    com_rev = pd.read_csv(\"Data/gb_beer_reviews.csv\")\n",
    "    hub_rev = pd.read_csv(\"Data/gb_beer_reviews.csv\")\n",
    "    nn_rev = pd.read_csv(\"Data/gb_beer_reviews.csv\")\n",
    "    \n",
    "    usr_type = profile(usr_id,usr_level)\n",
    "    beers = []\n",
    "    hub_rec = random.sample(hub(hub_rev, g),5)\n",
    "    for x in hub_rec: \n",
    "            beers.append(beer_list.loc[beer_list['beer'] == x, 'name'].iloc[0])\n",
    "    \n",
    "    # if user selected is a 'heavy' user, use community algorithm\n",
    "    if usr_type == 1:\n",
    "        com = random.sample(beer_by_com(g, usr_id, edges, com_rev),5)\n",
    "        for x in com: \n",
    "            beers.append(beer_list.loc[beer_list['beer'] == x, 'name'].iloc[0])\n",
    "        \n",
    "    # if user selected is an 'occasional' user, use alter's alter algorithm\n",
    "    else:\n",
    "        alter = random.sample(NN(usr_id,usr_usr,pop,nn_rev),5)\n",
    "        for x in alter: \n",
    "            beers.append(beer_list.loc[beer_list['beer'] == x, 'name'].iloc[0])\n",
    "    return beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:43:02.024116Z",
     "start_time": "2018-12-13T02:43:02.019322Z"
    }
   },
   "outputs": [],
   "source": [
    "usr_id = '988388'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:47:09.503984Z",
     "start_time": "2018-12-13T02:45:08.447821Z"
    }
   },
   "outputs": [],
   "source": [
    "recommender = recommend(usr_id, usr_level, g, edges, usr_usr, pop, beer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:47:26.573089Z",
     "start_time": "2018-12-13T02:47:26.553719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fourpure / Devils Peak - Coastline',\n",
       " 'Pintle',\n",
       " 'What the Water Wanted',\n",
       " 'Hedonic Escalation',\n",
       " 'Hazy Jane',\n",
       " 'Railway Porter',\n",
       " 'Edinburgh Tattoo Strong Ale',\n",
       " 'DDH IPA Citra BBC',\n",
       " 'Badger Best Bitter',\n",
       " 'Stranded Bunny Porter']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecturer's comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Group 3 members,\n",
    "\n",
    "let met first recall the assessment criteria that apply to the SMM635 final course project: i) appropriate use of notions and frameworks discussed in class; ii) effectiveness of the proposed answer or solution; iii) originality/creativity of the proposed answer or solution; iv) organization an clarity of submitted materials. All criteria carry-out equal weight in terms of mark.\n",
    "\n",
    "I am very positively impressed by the quality of your submission. Great job!\n",
    "\n",
    "What works:\n",
    "\n",
    "- the supporting documentation is clear and well-organized. Also, I like your choice to keep the code and the documentation for your project in the same document â€• very useful when it comes to share and cooperate on Python projects\n",
    "\n",
    "- your recommender properly leverages a number of network aspects â€• some of these are 'micro' elements (individual nodes and their positions), some others concern the 'ego-network' (an ego's neighbors or neighbors' neighbors), or the internal organization of the network (i.e., the community structure). Even more important, you argument the choice of each individual network aspect with sound theoretical arguments.  Well done.\n",
    "\n",
    "- I like the idea of providing the recommender in different flavors, according to the status of the target user\n",
    "  \n",
    "What can be improved:\n",
    "\n",
    "- you do not show how and to what extent the set of recommendations changes as you expand on (different) network elements. A systematic comparison would have made this project outstanding.\n",
    "  \n",
    "Taking all these points into considerations, the mark of your project is 74 (bonus points from the presentation session are included).\n",
    "\n",
    "Best,\n",
    "\n",
    "Simone"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 427.666666,
   "position": {
    "height": "40px",
    "left": "572px",
    "right": "20px",
    "top": "7px",
    "width": "695px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
